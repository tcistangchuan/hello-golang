https://zhuanlan.zhihu.com/p/93398256



- golang笔试题&面试题

  ```
  基础笔试题：
  https://blog.csdn.net/itcastcpp/article/details/80462619
  
  大厂面试题：
  https://blog.csdn.net/helen920318/article/details/106658780
  
  大厂面试准备方向：
  https://github.com/tcistangchuan/LeetCode
  ```

- 难点：

  ```
  1.tcp丢包怎么解决
  
  2.零拷贝
  参考：https://www.jianshu.com/p/fad3339e3448
  
  3.kafka为啥性能高
  https://segmentfault.com/a/1190000022990814
  （1）分区。每个partition存储的是不同的数据
   (2)消息顺序追加。在日志文件的最后追加新的消息,顺序写磁盘的速度是非常快的。
   (3)页缓存。页缓存是操作系统实现的一种主要的磁盘缓存，以此用来减少对磁盘I/O的操作。
   (4)零拷贝。零拷贝技术是一种避免CPU将数据从一块存储拷贝到另一块存储的技术。Kafka使用零拷贝技术将数据直接从磁盘复制到网卡设备缓冲区中，而不需要经过应用程序的转发。
   
  8.kafka重复消费原因以及处理方式
  	参考：https://segmentfault.com/a/1190000023282843
  	重复消费的可能原因：
  	（1）消费后的数据，程序挂了，offset没有提交
  	（2）消费数据后，offset还未提交前，触发了rebalance,partion的消息被分到其他consumer被重新消费。比如消费者取消订阅topic或者消费超时和partition断开连接。
  	处理方式：为了确保consumer消费的数据一定是接着上一次consumer消费的数据，consumer消费时，记录本次取出的第一条数据，将其offset和上次consumer最后消费的offset进行对比，如果相同则继续消费。如果不同，则停止消费，检查原因。
  
  1x.kafka消息丢失原因和解决方式：
  	(1)生产者没有推送：
  		send方法之后没有，没有获取发送结果，默认发送成功。如果消息发送失败的话，我们检查失败的原因之后重新发送即可！另外这里推荐为 Producer 的retries（重试次数）设置一个比较合理的值，一般是 3 ，但是为了保证消息不丢失的话一般会设置比较大一点。设置完成之后，当出现网络问题之后能够自动重试消息发送，避免消息丢失。另外，建议还要设置重试间隔，因为间隔太小的话重试的效果就不明显了，网络波动一次你3次一下子就重试完了。
  	（2）消费者消费失败：
  		当消费者拉取到了分区的某个消息之后，消费者会自动提交了 offset。自动提交的话会有一个问题，试想一下，当消费者刚拿到这个消息准备进行真正消费的时候，突然挂掉了，消息实际上并没有被消费，但是 offset 却被自动提交了。解决办法也比较粗暴，我们手动关闭自动提交 offset，每次在真正消费完消息之后之后再自己手动提交 offset 。
  		
  1x kafka中partition和消费者对应关系
  	参考：https://blog.csdn.net/mxw2552261/article/details/101441652
  	Kafka 通过偏移量（offset）可以保证消息在分区内的顺序性。
    kafka 为了保证同一类型的消息顺序性（FIFO），一个partition只能被同一组的一个consumer消费，不同组的consumer可以消费同一个partition。但是一个consumer可以消费多个partition
  
  1.x 什么是kafka的Rebalance
    (1)Rebalance 本质上是一种协议，规定了一个 Consumer Group 下的所有 consumer 如何达成一致，来分配订阅 Topic 的每个分区。
    (2)kafka的rebalance条件:
    条件1：有新的consumer加入
    条件2：旧的consumer挂了
    条件3：coordinator挂了，集群选举出新的coordinator（0.10 特有的）
    条件4：topic的partition新加
    条件5：consumer调用unsubscrible()，取消topic的订阅
    (3)Rebalance有什么影响:
  Rebalance本身是Kafka集群的一个保护设定，用于剔除掉无法消费或者过慢的消费者，然后由于我们的数据量较大，同时后续消费后的数据写入需要走网络IO，很有可能存在依赖的第三方服务存在慢的情况而导致我们超时。
  Rebalance对我们数据的影响主要有以下几点：
    a.数据重复消费: 消费过的数据由于提交offset任务也会失败，在partition被分配给其他消费者的时候，会造成重复消费，数据重复且增加集群压力
    b.Rebalance扩散到整个ConsumerGroup的所有消费者，因为一个消费者的退出，导致整个Group进行了Rebalance，并在一个比较慢的时间内达到稳定状态，影响面较大
    c.频繁的Rebalance反而降低了消息的消费速度，大部分时间都在重复消费和Rebalance
    d.数据不能及时消费，会累积lag，在Kafka的TTL之后会丢弃数据
  
   Kafka集群消息积压问题及处理策略
   增加消费者个数，达到提高消费速度的目的。
  
  10.kafka集群。
  
  4.grpc为啥这么高效，http2协议的优点和
  （1）多路IO复用技术，一个tcp连接同时处理多个请求/响应（都是同一个客户端发起的）。
  （2）http头部压缩。
  （3）服务端主动推送。
  
  12.redis哨兵模式集群
  （1）哨兵是以多哨兵模式监控的，多个哨兵之间也会互相监控。
  （2）主节点宕机，从节点切换成主节点，需要多个哨兵投票决定。
  
  6.redis cluster集群：
  参考：https://segmentfault.com/a/1190000022808576
    cluster模式集群采用的哈希槽
    key->槽的编号->槽对应的节点
  需要注意的是：
    (1) hash卡槽只会分配给每个片区的主节点上，从节点不会分配卡槽，从节点会同步master上的hash槽。
    (2)每个hash卡槽可以存放多个Key，每一个数据key对应一个hash槽。
    (3)hash卡槽的目的是确认数据存放到哪个片区的Redis主节点上，实现Redis集群分摊Key。
    (4) 每个片区的Redis主节点卡槽数都对应一个范围，多个片区之间卡槽数范围是等比分配的。比如：存在3个片区对应3个Redis主机，那么3个Redis主机的卡槽总数分别是：16384/3。3个Redis主机的卡槽范围分别是：
          第一台Redis主机：0~5461
          第二台Redis主机：5462 ~ 10922
          第三台Redis主机：10923~16383
    (5)写操作时，会根据Key值计算出对应的卡槽所在的位置，再将数据存入卡槽区对应的master中；读数据也是一样，通过key得到slot，再通过slot找到node获取数据（客户端读请求是打到任意节点上的，当请求的数据没有在接受请求的node上时，会出现重定向，后面有详细讲解）。
    (6)Redis Cluster的节点之间会共享消息，每个节点都会知道是哪个节点负责哪个范围内的数据槽。所以客服端请求任意一个节点，都能获取到slot对应的node信息。
  
  
  6.redis哈希一致性
  
  12.redis优化
  （1）避免redis大key.
  	Redis限制每个String类型value大小不超过512MB， 实际开发中，不要超过10KB，否则会对CPU和网卡造成极大负载。 hash、list、set、zset元素个数不要超过5000。
  
  7.protobuf 为什么那么高效，为啥不用json或者xml
  参考：https://www.jianshu.com/p/72108f0aefca
    protobuf是一种序列化数据结构的协议/格式
    protobuf序列化后的大小是json的10分之一，是xml格式的20分之一，但是性能却是它们的5~100倍，
    （1）将value值拼接在一起，对应的key的顺序是参考tag中的编号来排序；
    （2）在tag当中记录两种信息，一个是value对应的字段的编号，另一个是value的数据类型（比如是整形还是字符串等）
    （3）在protobuf中，tag使用二进制进行存储，一般只会占据一个字节
  
  
  11.nginx负载均衡 如果主节点或者代理服务器挂掉了 咋办
  
  
  ```

  